"""Centralized prompt templates for training and evaluation consistency.

This module provides the single source of truth for all prompt templates used
throughout the pipeline. Both training (notebooks) and evaluation (runner.py)
should import from here to ensure consistency.

The prompt format follows the structure generated by RAGPipeline.prepare_prompt()
and stored in the dataset's `rag.prompt` field.
"""

from __future__ import annotations

import re
from collections.abc import Sequence
from typing import Any

# =============================================================================
# System Messages
# =============================================================================

RAG_SYSTEM_MESSAGE = (
    "You are a scientific research assistant who answers with concise, "
    "evidence-grounded prose and includes inline numeric citations like [1], [2], etc."
)

INSTRUCTION_ONLY_SYSTEM_MESSAGE = (
    "You are a scientific research assistant who provides clear, accurate, "
    "and well-structured answers to questions."
)

# =============================================================================
# Instruction Blocks
# =============================================================================

RAG_INSTRUCTIONS = (
    "Answer the question using the provided context. "
    "Cite the sources inline as [#] based on the order of the snippets. "
    "If the answer is not in the context, say you don't know."
)

RAG_TRAINED_NO_CONTEXT_INSTRUCTIONS = (
    "Answer the following question based on your knowledge. "
    "Do not include citations or source references as no sources are provided. "
    "Provide a clear and concise response."
)

# =============================================================================
# Context Normalization
# =============================================================================

_CONTEXT_NUMBER_PATTERN = re.compile(r"^\s*\[(\d+)\]")


def normalize_contexts(contexts: Sequence[Any]) -> list[str]:
    """Return contexts as trimmed strings with explicit numbering.

    If contexts are already numbered (e.g., "[1] text"), they are preserved.
    Otherwise, numbering is added.

    Args:
        contexts: Sequence of context strings or objects

    Returns:
        List of numbered context strings like "[1] context text"
    """
    processed = [str(ctx).strip() for ctx in contexts if ctx is not None]
    if not processed:
        return []
    # Check if all contexts are already numbered
    if all(_CONTEXT_NUMBER_PATTERN.match(ctx) for ctx in processed):
        return processed
    return [f"[{idx + 1}] {ctx}" for idx, ctx in enumerate(processed)]


# =============================================================================
# Prompt Builders
# =============================================================================


def build_rag_prompt(
    question: str,
    contexts: Sequence[str],
    *,
    extra_instructions: str | None = None,
) -> str:
    """Build RAG user prompt with contexts.

    This is the canonical RAG prompt format used throughout the pipeline.
    Both training and evaluation should use this format for consistency.

    Args:
        question: The question to answer
        contexts: List of context strings (will be normalized/numbered if needed)
        extra_instructions: Optional additional instructions to append

    Returns:
        Formatted prompt string

    Example output:
        Answer the question using the provided context. Cite the sources...

        Context:
        [1] First context text...

        [2] Second context text...

        Question: What is X?
        Answer:
    """
    question_text = question.strip()
    if not question_text:
        raise ValueError("Question cannot be empty")

    numbered_contexts = normalize_contexts(contexts)
    context_block = (
        "\n\n".join(numbered_contexts) if numbered_contexts else "(No contexts provided)"
    )

    instructions = RAG_INSTRUCTIONS
    if extra_instructions:
        instructions = f"{instructions} {extra_instructions.strip()}"

    return f"{instructions}\n\nContext:\n{context_block}\n\nQuestion: {question_text}\nAnswer:"


def build_instruction_only_prompt(question: str) -> str:
    """Build instruction-only prompt (no RAG contexts).

    Used for:
    - Condition 1: Base model without RAG
    - Condition 3: Instruction-only fine-tuned model without RAG

    Args:
        question: The question to answer

    Returns:
        Formatted prompt string
    """
    question_text = question.strip()
    if not question_text:
        raise ValueError("Question cannot be empty for instruction-only mode")

    return f"Question: {question_text}\n\nAnswer:"


def build_rag_trained_no_context_prompt(question: str) -> str:
    """Build prompt for RAG-trained models evaluated WITHOUT contexts.

    Used for Condition 5: RAG-trained model evaluated without RAG contexts.
    This tests distribution shift (model trained WITH contexts, evaluated WITHOUT).

    The prompt explicitly instructs not to cite since no contexts are provided,
    to prevent spurious citations from a model trained to always cite.

    Args:
        question: The question to answer

    Returns:
        Formatted prompt string
    """
    question_text = question.strip()
    if not question_text:
        raise ValueError("Question cannot be empty")

    return f"{RAG_TRAINED_NO_CONTEXT_INSTRUCTIONS}\n\n" f"Question: {question_text}\n\nAnswer:"


# =============================================================================
# Chat Template Helpers
# =============================================================================


def build_chat_messages(
    user_content: str,
    assistant_response: str | None = None,
    *,
    system_message: str = RAG_SYSTEM_MESSAGE,
) -> list[dict[str, str]]:
    """Build chat messages list for tokenizer.apply_chat_template().

    Args:
        user_content: The user message (typically from build_rag_prompt or similar)
        assistant_response: Optional assistant response (for training)
        system_message: System message to use

    Returns:
        List of message dicts with 'role' and 'content' keys
    """
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_content},
    ]
    if assistant_response is not None:
        messages.append({"role": "assistant", "content": assistant_response})
    return messages


# =============================================================================
# Exports
# =============================================================================

__all__ = [
    # System messages
    "RAG_SYSTEM_MESSAGE",
    "INSTRUCTION_ONLY_SYSTEM_MESSAGE",
    # Instruction blocks
    "RAG_INSTRUCTIONS",
    "RAG_TRAINED_NO_CONTEXT_INSTRUCTIONS",
    # Utilities
    "normalize_contexts",
    # Prompt builders
    "build_rag_prompt",
    "build_instruction_only_prompt",
    "build_rag_trained_no_context_prompt",
    "build_chat_messages",
]
