# Prompt Format Specification

## Overview

This document specifies the expected prompt formats for training and evaluation to ensure consistency across the pipeline. Adherence to these formats is critical for valid experimental comparisons.

## System Messages

### Instruction-Only Model

**Training System Message:**
```
"You are a research paper assistant."
```

**Modelfile System Message:**
```
"You are a research paper assistant."
```

**Evaluation User Content Format:**
```
Question: {instruction}

Answer:
```

**Important Notes:**
- System message comes from Modelfile during evaluation (via Ollama)
- User content should NOT include system-like text to avoid duplication
- The evaluation runner's `_build_instruction_only_prompt()` handles this formatting

### RAG-Trained Model

**Training System Message:**
```
"You are a scientific research assistant who answers with concise, evidence-grounded prose and includes inline numeric citations like [1], [2], etc."
```

**Modelfile System Message:**
```
"You are a scientific research assistant who answers with concise, evidence-grounded prose and includes inline numeric citations like [1], [2], etc."
```

**Evaluation User Content Format:**
- Uses pre-built RAG prompt from `offline_dataset.jsonl` (`rag.prompt` field)
- Format includes contexts and citation instructions as generated by `RAGPipeline.prepare_prompt()`

## Prompt Format Rules

### 1. System Message Consistency

**Rule**: System messages in Modelfiles MUST exactly match training system messages.

**Rationale**: Mismatched system messages cause distribution shift between training and evaluation, invalidating experimental comparisons.

**Validation**: Use `validate_modelfile_system_message()` from `beyond_the_cutoff.utils.prompt_validation`

### 2. No System Text in User Content (Instruction Mode)

**Rule**: For instruction-only mode, user content must NOT include system-like instructions.

**Rationale**: Ollama applies Modelfile system messages automatically. Including system text in user content causes duplication and confusion.

**Example - ❌ WRONG:**
```
"You are a research paper assistant. Answer the following question based on your knowledge.

Question: What is X?

Answer:"
```

**Example - ✅ CORRECT:**
```
"Question: What is X?

Answer:"
```

### 3. RAG Prompt Format

**Rule**: RAG prompts should use the format generated by `RAGPipeline.prepare_prompt()`.

**Format:**
```
You are a research paper assistant. Answer the question using the provided context. Cite the sources inline as [#] based on the order of the snippets. If the answer is not in the context, say you don't know.

Context:
[1] First context snippet...
[2] Second context snippet...

Question: {instruction}
Answer:
```

**Note**: This format is generated during offline dataset creation and stored in `rag.prompt` field.

## Training Format

### Instruction-Only Training

Uses chat template format:
```python
messages = [
    {
        "role": "system",
        "content": "You are a research paper assistant.",
    },
    {
        "role": "user",
        "content": "You are a research paper assistant. Answer the following question based on your knowledge.\n\nQuestion: {instruction}\n\nAnswer:",
    },
    {
        "role": "assistant",
        "content": "{expected_response}",
    },
]
```

**Note**: Training includes system-like text in user content for consistency with chat template format. This is acceptable during training but should NOT be replicated in evaluation (where Modelfile handles system message).

### RAG-Trained Training

Uses chat template format:
```python
messages = [
    {
        "role": "system",
        "content": "You are a scientific research assistant who answers with concise, evidence-grounded prose and includes inline numeric citations like [1], [2], etc.",
    },
    {
        "role": "user",
        "content": "{rag.prompt}",  # Pre-built RAG prompt from dataset
    },
    {
        "role": "assistant",
        "content": "{expected_response}",
    },
]
```

## Evaluation Format

### Instruction-Only Evaluation

**Ollama Processing:**
1. Modelfile applies system message: `"You are a research paper assistant."`
2. User content is: `"Question: {instruction}\n\nAnswer:"`
3. Ollama combines them using chat template

**Code Location**: `src/beyond_the_cutoff/evaluation/runner.py::_build_instruction_only_prompt()`

### RAG Evaluation

**Ollama Processing:**
1. Modelfile applies system message (citation instructions)
2. User content is pre-built RAG prompt from dataset
3. Ollama combines them using chat template

**Code Location**: `src/beyond_the_cutoff/evaluation/runner.py::run_evaluation()` (RAG mode)

## Validation

Use the validation utilities in `beyond_the_cutoff.utils.prompt_validation`:

```python
from beyond_the_cutoff.utils.prompt_validation import (
    validate_prompt_format_consistency,
    validate_modelfile_system_message,
)

# Validate Modelfile matches training
issues = validate_modelfile_system_message(
    Path("ollama/Modelfile.instruction_only"),
    "You are a research paper assistant.",
)

# Validate prompt format consistency
issues = validate_prompt_format_consistency(
    training_system_message="You are a research paper assistant.",
    modelfile_system_message="You are a research paper assistant.",
    evaluation_prompt="Question: What is X?\n\nAnswer:",
    mode="instruction",
)
```

## Common Mistakes

1. **Including system text in instruction-only user content**
   - ❌ Wrong: `"You are a research paper assistant. Question: X?\n\nAnswer:"`
   - ✅ Correct: `"Question: X?\n\nAnswer:"`

2. **Mismatched system messages between training and Modelfile**
   - ❌ Wrong: Training uses "research paper assistant", Modelfile uses "scientific research assistant"
   - ✅ Correct: Both use identical system messages

3. **Using different system messages for same model in different conditions**
   - ❌ Wrong: Instruction-only model uses different system message for FT-only vs FT+RAG
   - ✅ Correct: Same model uses same system message (contexts come in user content)

## References

- Training notebooks: `notebooks/finetuning/lora_science_v1_instruction_only.ipynb`, `lora_science_v1.ipynb`
- Modelfiles: `ollama/Modelfile.instruction_only`, `ollama/Modelfile.rag_trained`
- Evaluation runner: `src/beyond_the_cutoff/evaluation/runner.py`
- Validation utilities: `src/beyond_the_cutoff/utils/prompt_validation.py`
