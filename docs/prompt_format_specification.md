# Prompt Format Specification

## Overview

This document specifies the expected prompt formats for training and evaluation to ensure consistency across the pipeline. Adherence to these formats is critical for valid experimental comparisons.

## System Messages

### Instruction-Only Model

**Training System Message:**
```
"You are a research paper assistant."
```

**Modelfile System Message:**
```
"You are a research paper assistant."
```

**Evaluation User Content Format:**
```
Question: {instruction}

Answer:
```

**Important Notes:**
- System message comes from Modelfile during evaluation (via Ollama)
- User content should NOT include system-like text to avoid duplication
- The evaluation runner's `_build_instruction_only_prompt()` handles this formatting

### RAG-Trained Model

**Training System Message:**
```
"You are a scientific research assistant who answers with concise, evidence-grounded prose and includes inline numeric citations like [1], [2], etc."
```

**Modelfile System Message:**
```
"You are a scientific research assistant who answers with concise, evidence-grounded prose and includes inline numeric citations like [1], [2], etc."
```

**Evaluation User Content Format:**
- Uses pre-built RAG prompt from `offline_dataset.jsonl` (`rag.prompt` field)
- Format includes contexts and citation instructions as generated by `RAGPipeline.prepare_prompt()`

## Prompt Format Rules

### 1. System Message Consistency

**Rule**: System messages in Modelfiles MUST exactly match training system messages.

**Rationale**: Mismatched system messages cause distribution shift between training and evaluation, invalidating experimental comparisons.

**Validation**: Use `validate_modelfile_system_message()` from `beyond_the_cutoff.utils.prompt_validation`

### 2. No System Text in User Content (Instruction Mode)

**Rule**: For instruction-only mode, user content must NOT include system-like instructions.

**Rationale**: Ollama applies Modelfile system messages automatically. Including system text in user content causes duplication and confusion.

**Example - ❌ WRONG:**
```
"You are a research paper assistant. Answer the following question based on your knowledge.

Question: What is X?

Answer:"
```

**Example - ✅ CORRECT:**
```
"Question: What is X?

Answer:"
```

### 3. RAG Prompt Format

**Rule**: RAG prompts should use the format generated by `RAGPipeline.prepare_prompt()`.

**Important**: RAG prompts stored in the dataset (`rag.prompt` field) should contain **only user content**, without system text. The system message is provided separately via Modelfile during evaluation (or via chat template during training). Including system text in the prompt causes duplication and potential distribution shift.

**Format:**
```
Answer the question using the provided context. Cite the sources inline as [#] based on the order of the snippets. If the answer is not in the context, say you don't know.

Context:
[1] First context snippet...
[2] Second context snippet...

Question: {instruction}
Answer:
```

**Note**: This format is generated during offline dataset creation and stored in `rag.prompt` field. The `RAGPipeline._build_prompt()` method generates prompts without system text to ensure consistency with Modelfile system messages.

## Training Format

### Instruction-Only Training

Uses chat template format:
```python
messages = [
    {
        "role": "system",
        "content": "You are a research paper assistant.",
    },
    {
        "role": "user",
        "content": "Question: {instruction}\n\nAnswer:",
    },
    {
        "role": "assistant",
        "content": "{expected_response}",
    },
]
```

**Note**: System message is provided separately in the chat template. User content contains only the question/answer format. During evaluation, the Modelfile provides the system message, so user content should NOT duplicate it.

### RAG-Trained Training

Uses chat template format:
```python
messages = [
    {
        "role": "system",
        "content": "You are a scientific research assistant who answers with concise, evidence-grounded prose and includes inline numeric citations like [1], [2], etc.",
    },
    {
        "role": "user",
        "content": "{rag.prompt}",  # Pre-built RAG prompt from dataset
    },
    {
        "role": "assistant",
        "content": "{expected_response}",
    },
]
```

## Evaluation Format

### Instruction-Only Evaluation

**Ollama Processing:**
1. Modelfile applies system message: `"You are a research paper assistant."`
2. User content is: `"Question: {instruction}\n\nAnswer:"`
3. Ollama combines them using chat template

**Code Location**: `src/beyond_the_cutoff/evaluation/runner.py::_build_instruction_only_prompt()`

### RAG Evaluation

**Standard RAG (RAG-trained models):**
1. Modelfile applies system message (citation instructions)
2. User content is pre-built RAG prompt from dataset
3. Ollama combines them using chat template

**Hybrid RAG (Condition 4 - Instruction-only model with RAG contexts):**
1. Modelfile applies system message: `"You are a research paper assistant."`
2. User content uses hybrid format that preserves training instruction structure:
   ```
   Question: {instruction}

   Context:
   [1] First context snippet...
   [2] Second context snippet...

   Answer using the provided context. Cite sources inline as [#] based on the order of the snippets.
   If the answer is not in the context, say you don't know.

   Answer:
   ```
3. This format preserves the training structure ("Question: ... Answer:") while adding RAG contexts between them, ensuring the model sees familiar instruction patterns while learning to use contexts.

**Code Location**:
- Standard RAG: `src/beyond_the_cutoff/evaluation/runner.py::run_evaluation()` (RAG mode)
- Hybrid RAG: `src/beyond_the_cutoff/evaluation/runner.py::_build_rag_prompt_for_instruction_only_model()`

## Validation

Use the validation utilities in `beyond_the_cutoff.utils.prompt_validation`:

```python
from beyond_the_cutoff.utils.prompt_validation import (
    validate_prompt_format_consistency,
    validate_modelfile_system_message,
    validate_rag_prompt_no_system_text,
)

# Validate Modelfile matches training
issues = validate_modelfile_system_message(
    Path("ollama/Modelfile.instruction_only"),
    "You are a research paper assistant.",
)

# Validate prompt format consistency
issues = validate_prompt_format_consistency(
    training_system_message="You are a research paper assistant.",
    modelfile_system_message="You are a research paper assistant.",
    evaluation_prompt="Question: What is X?\n\nAnswer:",
    mode="instruction",
)

# Validate RAG prompt doesn't contain system text
rag_prompt = "Answer the question using the provided context..."
issues = validate_rag_prompt_no_system_text(rag_prompt)
```

**Note**: The evaluation runner automatically validates RAG prompts during evaluation and warns if system text is detected.

## Common Mistakes

1. **Including system text in instruction-only user content**
   - ❌ Wrong: `"You are a research paper assistant. Question: X?\n\nAnswer:"`
   - ✅ Correct: `"Question: X?\n\nAnswer:"`

2. **Including system text in RAG prompts**
   - ❌ Wrong: `"You are a research paper assistant. Answer the question using the provided context..."`
   - ✅ Correct: `"Answer the question using the provided context..."` (system message provided separately via Modelfile)

3. **Mismatched system messages between training and Modelfile**
   - ❌ Wrong: Training uses "research paper assistant", Modelfile uses "scientific research assistant"
   - ✅ Correct: Both use identical system messages

4. **Using different system messages for same model in different conditions**
   - ❌ Wrong: Instruction-only model uses different system message for FT-only vs FT+RAG
   - ✅ Correct: Same model uses same system message (contexts come in user content)

## References

- Training notebooks: `notebooks/finetuning/lora_science_v1_instruction_only.ipynb`, `lora_science_v1.ipynb`
- Modelfiles: `ollama/Modelfile.instruction_only`, `ollama/Modelfile.rag_trained`
- Evaluation runner: `src/beyond_the_cutoff/evaluation/runner.py`
- Validation utilities: `src/beyond_the_cutoff/utils/prompt_validation.py`
