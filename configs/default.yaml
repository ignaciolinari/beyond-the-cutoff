project:
  name: "Beyond the Cutoff"
  seed: 42
paths:
  raw_data: ../data/raw
  processed_data: ../data/processed
  external_data: ../data/external
retrieval:
  vector_store: faiss
  embedding_model: BAAI/bge-m3
  chunk_size: 800
  chunk_overlap: 120
  top_k: 4
  max_context_chars: 6000
  chunking_strategy: sentences
  reranker_model: BAAI/bge-reranker-v2-m3
fine_tuning:
  base_model: Qwen/Qwen2.5-0.5B-Instruct
  adapter_output_dir: ../outputs/adapters
  lora_rank: 16
  learning_rate: 0.0001
  batch_size: 4
  gradient_accumulation_steps: 4
  max_steps: 1000
evaluation:
  metrics:
    - factuality
    - citation_accuracy
    - bleu
    - bertscore
  qa_dataset_path: ../evaluation/datasets/qa_pairs.jsonl
  summary_dataset_path: ../evaluation/datasets/summaries.jsonl
  offline_tasks_path: ../evaluation/datasets/offline_tasks.jsonl
  offline_dataset_path: ../evaluation/datasets/offline_dataset.jsonl
dataset_generation:
  generator:
    provider: ollama
    model: qwen2.5:7b-instruct-q4_K_M
    host: http://localhost
    port: 11434
    timeout: 120.0
    device: auto  # retained for interface parity with transformers backend
    torch_dtype: auto
    max_new_tokens: 768
    temperature: 0.5
    top_p: 0.95
    repetition_penalty: 1.05
    stop_sequences: []
  questions_per_document: 8
  summary_prompts_per_document: 2
  citation_prompts_per_document: 2
  contextual_prompts_per_document: 2
  min_questions_per_document: 6
  min_summary_prompts_per_document: 2
  min_citation_prompts_per_document: 1
  min_contextual_prompts_per_document: 1
  max_chunks_per_document: 8
  max_chars_per_chunk: 1600
  max_documents: null
  max_document_tokens: 25000
  max_document_pages: 50
  seed: 42
  parse_retries: 2
  citation_rewrite_attempts: 1
  min_citation_coverage: 0.2
  output_dataset_path: ../evaluation/datasets/offline_dataset.jsonl
  raw_tasks_path: ../evaluation/datasets/offline_tasks.jsonl
inference:
  provider: ollama
  model: qwen2.5:0.5b-instruct
  host: http://localhost
  port: 11434
  timeout: 480.0
  device: auto
  torch_dtype: auto
  max_new_tokens: 512
  temperature: 0.0
  top_p: 0.9
  repetition_penalty: 1.05
  stop_sequences:
    - "<|im_start|>"
    - "<|im_end|>"
  # Swap to qwen2.5:3b-instruct once the 0.5B experiment sequence finishes.
