provider: ollama
# F16 (full precision) version of RAG-trained fine-tuned model
# This is for quantization comparison - NOT for regular evaluation
# Size: ~988MB vs ~397MB for Q4_K_M
model: lora_science_0p5_f16
model_type: rag_trained
host: http://localhost
port: 11434
timeout: 480.0
device: auto
torch_dtype: auto
max_new_tokens: 512
temperature: 0.0
top_p: 0.9
repetition_penalty: 1.05
stop_sequences:
  - "<|im_start|>"
  - "<|im_end|>"
