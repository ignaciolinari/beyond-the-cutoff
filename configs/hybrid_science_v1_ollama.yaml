provider: ollama
# Update `model` to match the Ollama tag you create from the merged LoRA adapter.
model: lora_science_0p5
host: http://localhost
port: 11434
timeout: 480.0
device: auto
torch_dtype: auto
max_new_tokens: 512
temperature: 0.0
top_p: 0.9
repetition_penalty: 1.05
stop_sequences:
  - "<|im_start|>"
  - "<|im_end|>"
