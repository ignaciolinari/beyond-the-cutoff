provider: ollama
# Model tag for instruction-only fine-tuned model used WITH RAG contexts
# This is the same model as FT-only, but evaluated WITH RAG contexts
# The model is trained instruction-only (without contexts), but we use it with RAG at evaluation time
# NOTE: This is condition #3 in the comparison. For optimal RAG+FT performance, use lora_science_v1_rag_trained_ollama.yaml instead
model: lora_science_0p5_instruction_only
host: http://localhost
port: 11434
timeout: 480.0
device: auto
torch_dtype: auto
max_new_tokens: 512
temperature: 0.0
top_p: 0.9
repetition_penalty: 1.05
stop_sequences:
  - "<|im_start|>"
  - "<|im_end|>"
