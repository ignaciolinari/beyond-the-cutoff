{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9dadf17",
   "metadata": {},
   "source": [
    "# Corpus Quality Checks\n",
    "\n",
    "This notebook inspects the processed corpus to verify text coverage, sidecar availability, and metadata consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a6484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data/processed\"\n",
    "RAW_DIR = PROJECT_ROOT / \"data/raw/arxiv_2025\"\n",
    "DATA_QUALITY_DIR = PROJECT_ROOT / \"evaluation/results/data_quality\"\n",
    "\n",
    "MANIFEST_PATH = PROCESSED_DIR / \"manifest.json\"\n",
    "METADATA_JSONL = RAW_DIR / \"metadata.jsonl\"\n",
    "SELECTION_LOG = RAW_DIR / \"selection_log.jsonl\"\n",
    "\n",
    "plt.rcParams.update({\"figure.figsize\": (8, 4), \"axes.grid\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_manifest(path: Path) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Processed manifest missing at {path}\")\n",
    "    data = json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "    docs = data.get(\"documents\", [])\n",
    "    if not isinstance(docs, list):\n",
    "        raise TypeError(\"Manifest documents field must be a list\")\n",
    "    records: list[dict[str, Any]] = []\n",
    "    for entry in docs:\n",
    "        if not isinstance(entry, dict):\n",
    "            continue\n",
    "        record = entry.copy()\n",
    "        record[\"text_path\"] = PROCESSED_DIR / record[\"text_path\"]\n",
    "        pages_path = record.get(\"pages_path\")\n",
    "        record[\"pages_path\"] = PROCESSED_DIR / pages_path if pages_path else None\n",
    "        records.append(record)\n",
    "    frame = pd.DataFrame(records)\n",
    "    if not frame.empty:\n",
    "        frame[\"has_pages_sidecar\"] = frame[\"pages_path\"].apply(\n",
    "            lambda p: bool(p and Path(p).exists())\n",
    "        )\n",
    "    return frame\n",
    "\n",
    "\n",
    "def load_metadata(jsonl_path: Path) -> pd.DataFrame:\n",
    "    if not jsonl_path.exists():\n",
    "        raise FileNotFoundError(f\"Metadata JSONL missing at {jsonl_path}\")\n",
    "    rows: list[dict[str, Any]] = []\n",
    "    with jsonl_path.open(\"r\", encoding=\"utf-8\") as handle:\n",
    "        for line in handle:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            payload = json.loads(line)\n",
    "            if isinstance(payload, dict):\n",
    "                rows.append(payload)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def estimate_tokens(text_path: Path) -> tuple[int, int]:\n",
    "    text = text_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    words = text.split()\n",
    "    return len(text), len(words)\n",
    "\n",
    "\n",
    "def ensure_output_dir(path: Path) -> None:\n",
    "    path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_df = load_manifest(MANIFEST_PATH)\n",
    "display(manifest_df.head())\n",
    "print(f\"Total documents in manifest: {len(manifest_df)}\")\n",
    "if not manifest_df.empty:\n",
    "    total_bytes = manifest_df[\"bytes\"].sum()\n",
    "    print(f\"Total text bytes: {total_bytes:,}\")\n",
    "    manifest_meta = json.loads(MANIFEST_PATH.read_text(encoding=\"utf-8\"))\n",
    "    print(f\"Manifest generated_at: {manifest_meta.get('generated_at', 'unknown')}\")\n",
    "    print(f\"Manifest total_documents: {manifest_meta.get('total_documents', 'unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7447f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = load_metadata(METADATA_JSONL)\n",
    "print(f\"Metadata rows: {len(metadata_df)}\")\n",
    "if not metadata_df.empty:\n",
    "    duplicates = metadata_df[\"arxiv_id\"].str.split(\"v\").str[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7951e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if manifest_df.empty:\n",
    "    raise RuntimeError(\"Manifest is empty; aborting QA metrics.\")\n",
    "\n",
    "byte_lengths: list[int] = []\n",
    "token_counts: list[int] = []\n",
    "sidecar_pages: list[float] = []\n",
    "for row in manifest_df.itertuples(index=False):\n",
    "    text_path = Path(row.text_path)\n",
    "    if not text_path.exists():\n",
    "        continue\n",
    "    chars, tokens = estimate_tokens(text_path)\n",
    "    byte_lengths.append(chars)\n",
    "    token_counts.append(tokens)\n",
    "    pages_path = row.pages_path\n",
    "    if pages_path:\n",
    "        with Path(pages_path).open(\"r\", encoding=\"utf-8\") as handle:\n",
    "            page_counter = sum(1 for _ in handle)\n",
    "    else:\n",
    "        page_counter = float(\"nan\")\n",
    "    sidecar_pages.append(page_counter)\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    {\n",
    "        \"tokens\": token_counts,\n",
    "        \"chars\": byte_lengths,\n",
    "        \"sidecar_pages\": sidecar_pages,\n",
    "    }\n",
    ")\n",
    "summary_stats = summary.describe(percentiles=[0.05, 0.5, 0.95])\n",
    "display(summary_stats)\n",
    "\n",
    "print(\"Documents missing sidecars:\", (~manifest_df[\"has_pages_sidecar\"]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92143f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].hist(summary[\"tokens\"], bins=30, color=\"#1f77b4\")\n",
    "axes[0].set_title(\"Token count distribution\")\n",
    "axes[0].set_xlabel(\"Tokens per document\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "axes[1].hist(summary[\"sidecar_pages\"].dropna(), bins=30, color=\"#ff7f0e\")\n",
    "axes[1].set_title(\"Pages per sidecar\")\n",
    "axes[1].set_xlabel(\"Pages\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e1732",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_output_dir(DATA_QUALITY_DIR / \"plots\")\n",
    "output_csv = DATA_QUALITY_DIR / \"qa_summary_stats.csv\"\n",
    "summary_stats.to_csv(output_csv, index=True)\n",
    "print(f\"Wrote summary stats to {output_csv}\")\n",
    "\n",
    "selection_entries: list[dict[str, Any]] = []\n",
    "if SELECTION_LOG.exists():\n",
    "    with SELECTION_LOG.open(\"r\", encoding=\"utf-8\") as handle:\n",
    "        for line in handle:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            selection_entries.append(json.loads(line))\n",
    "if selection_entries:\n",
    "    batches = Counter(entry.get(\"selection_batch\", \"unknown\") for entry in selection_entries)\n",
    "    print(\"Selection batches recorded:\", batches)\n",
    "else:\n",
    "    print(\"No selection log entries found; ensure selection_log.jsonl is populated in future runs.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
